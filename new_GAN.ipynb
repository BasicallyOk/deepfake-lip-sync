{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 18:34:06.429777: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-17 18:34:06.429809: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-17 18:34:06.429836: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-17 18:34:06.436670: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-17 18:34:07.121947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# essentials\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from utils.hparams import hparams as hp \n",
    "import utils.audio as audio\n",
    "\n",
    "# misc\n",
    "import os\n",
    "import ntpath\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from datetime import datetime\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv() # allow using system specific data\n",
    "\n",
    "CURRENT_EPOCH = 0 # This is to combat kernel crashing \n",
    "EPOCHS = 20000\n",
    "BATCH_SIZE = 100\n",
    "TEST_BATCH_SIZE = 10\n",
    "BATCH_DATA_PATH = os.environ.get(\"BATCH_DATA_PATH\")\n",
    "GENERATED_IMAGES_PATH = os.environ.get(\"GENERATED_IMAGES_PATH\")\n",
    "SAVED_MODELS_PATH = os.environ.get(\"SAVED_MODELS_PATH\")\n",
    "DATASET_PATH = os.environ.get(\"DATASET_PATH\")\n",
    "TEST_DATASET_PATH = os.environ.get(\"TEST_DATASET_PATH\")\n",
    "\n",
    "# Image and audio settings, must be verified beforehands\n",
    "IMAGE_SHAPE = (64, 64, 3)\n",
    "AUDIO_SPECTROGRAM_SHAPE = (4, 601, 1)\n",
    "MASKED_IMAGE_SHAPE = (32, 64, 3)\n",
    "# most videos are 10 seconds, so this number line up with the expected frame rate\n",
    "AVERAGE_FRAME_PER_VIDEO = 217 # number of frames / number of audio files\n",
    "\n",
    "MODEL_NAME = os.environ.get(\"MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Batch Data\n",
    "### Pre-determined randomized batches to avoid wasting time randomizing it on the fly.\n",
    "`BATCH_DATA` is structured as a 3D array (dictionary here but the key is the index so same thing) of size `EPOCHS*BATCH_SIZE*2`.\\\n",
    "Every epoch, `BATCH_DATA` is called to fetch a certain epoch, which returns the array of size `BATCH_SIZE*2`.\\\n",
    "The 2 names corresponds to the name of the image, as well as the reference, where the image is the one we mask and generate based on, while the reference is the reference image of the same face"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Input Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_image_path_gen(folder_path):\n",
    "    for file in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        if os.path.isfile(file_path):\n",
    "            yield file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ref_image_path_gen(folder_path):\n",
    "    \"\"\"\n",
    "    Generates reference frame path for each frame in the folder.\n",
    "    NOTE: this might not work as intended if there are more than 1 person in the video.\n",
    "    Assumes os.listdir returns the files in the same order (should be the case in most systems).\n",
    "    Returns: tuple\n",
    "        path: the path to the reference image\n",
    "        modify: whether to modify the image (if a reference cannot be found)\n",
    "    \"\"\"\n",
    "    # not a fan of the loop, but it is what it is\n",
    "    for file in os.listdir(folder_path):\n",
    "        path = os.path.join(folder_path, file)\n",
    "        if os.path.isfile(path):\n",
    "            counter = 0\n",
    "            video_name, frame_index = file.split(\"_\") # the frame file is <source_video>_<frame_index>\n",
    "            frame_index = int(frame_index.split(\".\")[0]) # remove the file extension\n",
    "            ref_frame_path = path\n",
    "            ref_frame_index = frame_index\n",
    "            # find a valid reference frame of the same person. Assumes each video is of a single person.\n",
    "            while ref_frame_index == frame_index or not os.path.exists(ref_frame_path):\n",
    "                ref_frame_index = random.randint(0, AVERAGE_FRAME_PER_VIDEO - 1)\n",
    "                ref_frame_path = os.path.join(folder_path, video_name + \"_\" + str(ref_frame_index) + \".png\")\n",
    "                counter+=1 # stop once counter reaches 10\n",
    "                if counter >= 10:\n",
    "                    yield path, True # return the same image, but we'll flip it\n",
    "            yield ref_frame_path, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_audio_window(spectrogram, start_frame_num):\n",
    "    \"\"\"\n",
    "    Get the audio spectrogram window corresponding to the frame.\n",
    "    \"\"\"\n",
    "    # I did some testing, there are 8 samples per second\n",
    "    start_idx = int(8 * (start_frame_num // hp.fps))\n",
    "    \n",
    "    end_idx = start_idx + 4 # half a second to provide some padding\n",
    "    if (spectrogram.shape[0] < end_idx):\n",
    "        return spectrogram[-4:, :]\n",
    "\n",
    "    return spectrogram[start_idx : end_idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_data(image_path, dataset_path):\n",
    "    \"\"\"\n",
    "    Load the audio data from the file.\n",
    "    \"\"\"\n",
    "    image_path = image_path.numpy().decode(\"utf-8\")\n",
    "    dataset_path = dataset_path.numpy().decode(\"utf-8\")\n",
    "    frame_name = ntpath.basename(image_path) # get the name without the path (should also work on windows)\n",
    "    video_name, frame_index = frame_name.split(\"_\") # the frame file is <source_video>_<frame_index>\n",
    "    frame_index = int(frame_index.split(\".\")[0]) # remove the file extension\n",
    "\n",
    "    audio_path = os.path.join(dataset_path, \"audio\", video_name + \".wav\")\n",
    "\n",
    "    wav = audio.load_wav(audio_path, hp.sample_rate)\n",
    "    # get the spectrogram, seems inefficient to do this every time\n",
    "    spectrogram = audio.melspectrogram(wav)\n",
    "    spectrogram_window = crop_audio_window(spectrogram, frame_index)\n",
    "    spectrogram_window = tf.expand_dims(spectrogram_window, axis=-1) # add channel dimension\n",
    "    spectrogram_window = tf.convert_to_tensor(spectrogram_window)\n",
    "    return spectrogram_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, modify):\n",
    "    \"\"\"\n",
    "    Load the image from the file.\n",
    "    Args:\n",
    "        image_path: the path to the image to load\n",
    "        modify: whether to modify this image TODO\n",
    "    \"\"\"\n",
    "    image_path = image_path.numpy().decode(\"utf-8\")\n",
    "        \n",
    "    raw = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_png(raw, channels=3)\n",
    "\n",
    "    image = tf.cast(image, tf.float32) / 255. # [0 - 1] range\n",
    "\n",
    "    if modify:\n",
    "        # add any transformations here\n",
    "        image = tf.image.flip_left_right(image)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_masked_image(original_image):\n",
    "    # crop out bottom half\n",
    "    masked_image = original_image[:32, :, :] # strange bug where the height is a [3] tensor\n",
    "    return masked_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batcher_from_directory(batch_size:int, dataset_path:str, shuffle=False,seed=None) -> tf.data.Dataset:\n",
    "    \"\"\"\n",
    "    Return a tensorflow Dataset object that returns images and spectrograms as required.\n",
    "    Partly inspired by https://github.com/keras-team/keras/blob/v3.3.3/keras/src/utils/image_dataset_utils.py\n",
    "    \n",
    "    Args:\n",
    "        batch_size: The batch size.\n",
    "        dataset_path: The path to the dataset folder which must contain the image folder and audio folder.\n",
    "        shuffle: Whether to shuffle the dataset. Default to False.\n",
    "        seed: The seed for the shuffle. Default to None.\n",
    "    \"\"\"\n",
    "    image_dataset_path = os.path.join(dataset_path, \"image\")\n",
    "    # create the foundation datasets\n",
    "    og_dataset = tf.data.Dataset.from_generator(lambda: original_image_path_gen(image_dataset_path), \n",
    "                                                output_signature=tf.TensorSpec(shape=(), dtype=tf.string))\n",
    "    og_dataset = og_dataset.repeat(None) # repeat indefinitely\n",
    "    ref_dataset = tf.data.Dataset.from_generator(lambda: ref_image_path_gen(image_dataset_path),\n",
    "                                                 output_signature=(tf.TensorSpec(shape=(), dtype=tf.string), \n",
    "                                                                   tf.TensorSpec(shape=(), dtype=tf.bool)))\n",
    "    ref_dataset = ref_dataset.repeat(None) # repeat indefinitely\n",
    "\n",
    "    # create the input datasets\n",
    "    og_image_dataset = og_dataset.map(lambda x: tf.py_function(load_image, [x, tf.convert_to_tensor(False, dtype=tf.bool)], tf.float32), \n",
    "                                        num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    masked_image_dataset = og_image_dataset.map(lambda x: tf.py_function(load_masked_image, [x], tf.float32),\n",
    "                                        num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ref_image_dataset = ref_dataset.map(lambda x, y: tf.py_function(load_image, [x, y], tf.float32), \n",
    "                                        num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    audio_spec_dataset = og_dataset.map(lambda x: tf.py_function(load_audio_data, [x, dataset_path], tf.float64),\n",
    "                                        num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    unsync_spec_dataset = ref_dataset.map(lambda x, _: tf.py_function(load_audio_data, [x, dataset_path], tf.float64),\n",
    "                                        num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    # ensure shape as tensorflow does not accept unknown shapes\n",
    "    og_image_dataset = og_image_dataset.map(lambda x: tf.ensure_shape(x, IMAGE_SHAPE))\n",
    "    masked_image_dataset = masked_image_dataset.map(lambda x: tf.ensure_shape(x, MASKED_IMAGE_SHAPE))\n",
    "    ref_image_dataset = ref_image_dataset.map(lambda x: tf.ensure_shape(x, IMAGE_SHAPE))\n",
    "    audio_spec_dataset = audio_spec_dataset.map(lambda x: tf.ensure_shape(x, AUDIO_SPECTROGRAM_SHAPE))\n",
    "    unsync_spec_dataset = unsync_spec_dataset.map(lambda x: tf.ensure_shape(x, AUDIO_SPECTROGRAM_SHAPE))\n",
    "    \n",
    "    # multi input using https://discuss.tensorflow.org/t/train-a-model-on-multiple-input-dataset/17829/4\n",
    "    full_dataset = tf.data.Dataset.zip((masked_image_dataset, ref_image_dataset, audio_spec_dataset, unsync_spec_dataset), og_image_dataset)\n",
    "    # if shuffle:\n",
    "    #     full_dataset = full_dataset.shuffle(buffer_size=batch_size * 8, seed=seed) # not sure why buffer size is such\n",
    "    \n",
    "    # batch\n",
    "    full_dataset = full_dataset.batch(batch_size=batch_size)\n",
    "    \n",
    "    return full_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "Batch generator technically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 18:34:08.363251: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 18:34:08.406497: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 18:34:08.406705: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 18:34:08.408093: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 18:34:08.408271: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 18:34:08.408428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 18:34:08.480786: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 18:34:08.481024: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 18:34:08.481238: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-17 18:34:08.481429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5138 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Ti, pci bus id: 0000:0a:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((TensorSpec(shape=(None, 32, 64, 3), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None),\n",
       "  TensorSpec(shape=(None, 4, 601, 1), dtype=tf.float64, name=None),\n",
       "  TensorSpec(shape=(None, 4, 601, 1), dtype=tf.float64, name=None)),\n",
       " TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = batcher_from_directory(hp.batch_size, DATASET_PATH)\n",
    "x_test = batcher_from_directory(TEST_BATCH_SIZE, TEST_DATASET_PATH)\n",
    "x_test.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the batcher\n",
    "x_test_iter = iter(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of original image:  (64, 64, 3)\n",
      "Shape of masked image:  (32, 64, 3)\n",
      "Shape of spectrogram window:  (4, 601, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.5, 63.5, 63.5, -0.5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, original_image = next(x_test_iter)\n",
    "masked_image, ref_image, spectrogram_window, _ = x\n",
    "\n",
    "print(\"Shape of original image: \", original_image[0].shape)\n",
    "print(\"Shape of masked image: \", masked_image[0].shape)\n",
    "print(\"Shape of spectrogram window: \", spectrogram_window[0].shape)\n",
    "\n",
    "# plot the images\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(masked_image[0])\n",
    "plt.title(\"Masked Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(ref_image[0])\n",
    "plt.title(\"Reference Image\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(original_image[0])\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity Encoders\n",
    "1 for generator (reference) 1 for discriminator (generated image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"id_encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gaussian_noise (GaussianNo  (None, 64, 64, 3)         0         \n",
      " ise)                                                            \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 16, 16, 16)        2368      \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 16, 16, 16)        64        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 8, 8, 64)          9280      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 8, 8, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 4, 4, 128)         512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 2, 2, 256)         295168    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 2, 2, 256)         1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " id_encoding (Flatten)       (None, 1024)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 382528 (1.46 MB)\n",
      "Trainable params: 381600 (1.46 MB)\n",
      "Non-trainable params: 928 (3.62 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "identity_encoder = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=IMAGE_SHAPE, name=\"ref_image_input\"),\n",
    "    keras.layers.GaussianNoise(0.1), # introduce some noise\n",
    "    keras.layers.Conv2D(16, 7, 4, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, 3, 2, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, 3, 2, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(256, 3, 2, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(name='id_encoding'),\n",
    "], name=\"id_encoder\")\n",
    "identity_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"id_encoder_disc\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 16, 16, 16)        2368      \n",
      "                                                                 \n",
      " batch_normalization_4 (Bat  (None, 16, 16, 16)        64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 64)          25664     \n",
      "                                                                 \n",
      " batch_normalization_5 (Bat  (None, 8, 8, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_6 (Bat  (None, 4, 4, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_7 (Bat  (None, 4, 4, 64)          256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " id_encoding_disc (Flatten)  (None, 1024)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 102720 (401.25 KB)\n",
      "Trainable params: 102304 (399.62 KB)\n",
      "Non-trainable params: 416 (1.62 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# sigmoid ensures euclidean distance is in [0,1]\n",
    "identity_encoder_disc = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=IMAGE_SHAPE, name=\"image_input\"),\n",
    "    keras.layers.Conv2D(16, 7, 4, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, 5, 2, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, 3, 2, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, 3, 1, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(name='id_encoding_disc'),\n",
    "], name=\"id_encoder_disc\")\n",
    "identity_encoder_disc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked Identity Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"masked_id\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 8, 16, 16)         2368      \n",
      "                                                                 \n",
      " batch_normalization_8 (Bat  (None, 8, 16, 16)         64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 4, 8, 32)          12832     \n",
      "                                                                 \n",
      " batch_normalization_9 (Bat  (None, 4, 8, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 2, 4, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_10 (Ba  (None, 2, 4, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 2, 4, 64)          4160      \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 2, 4, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " masked_id_encoding (Flatte  (None, 512)               0         \n",
      " n)                                                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38560 (150.62 KB)\n",
      "Trainable params: 38208 (149.25 KB)\n",
      "Non-trainable params: 352 (1.38 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "masked_id_encoder = keras.models.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=MASKED_IMAGE_SHAPE, name=\"masked_image_input\"),\n",
    "    keras.layers.Conv2D(16, 7, 4, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, 5, 2, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, 3, 2, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, 1, 1, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(name='masked_id_encoding'),\n",
    "], name=\"masked_id\")\n",
    "masked_id_encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio Encoder\n",
    "1 for generator 1 for discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"audio_encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 2, 101, 16)        800       \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 2, 101, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 2, 34, 32)         12832     \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 2, 34, 32)         128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 2, 12, 64)         18496     \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 2, 12, 64)         256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 2, 4, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 2, 4, 128)         512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " audio_encoding (Flatten)    (None, 1024)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106944 (417.75 KB)\n",
      "Trainable params: 106464 (415.88 KB)\n",
      "Non-trainable params: 480 (1.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# crazy parameters balooning at the end, but who knows?\n",
    "audio_encoder = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=AUDIO_SPECTROGRAM_SHAPE, name=\"audio_input\"),\n",
    "    keras.layers.Conv2D(16, 7, (2, 6), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, 5, (1, 3), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, 3, (1, 3), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, 3, (1, 3), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(name='audio_encoding'),\n",
    "], name=\"audio_encoder\")\n",
    "audio_encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"audio_encoder_disc\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 2, 101, 16)        800       \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 2, 101, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 2, 34, 32)         12832     \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 2, 34, 32)         128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 2, 12, 64)         18496     \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 2, 12, 64)         256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 2, 4, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 2, 4, 128)         512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " audio_encoding_disc (Flatt  (None, 1024)              0         \n",
      " en)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 106944 (417.75 KB)\n",
      "Trainable params: 106464 (415.88 KB)\n",
      "Non-trainable params: 480 (1.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# sigmoid ensures euclidean distance is in [0,1]\n",
    "audio_encoder_disc = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=AUDIO_SPECTROGRAM_SHAPE, name=\"audio_input\"),\n",
    "    keras.layers.Conv2D(16, 7, (2, 6), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, 5, (1, 3), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, 3, (1, 3), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, 3, (1, 3), padding='same', activation='sigmoid'), \n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(name='audio_encoding_disc'),\n",
    "], name=\"audio_encoder_disc\")\n",
    "audio_encoder_disc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deepfake Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"face_decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape (Reshape)           (None, 4, 4, 160)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 4, 8, 128)         184448    \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 4, 8, 128)         512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 8, 16, 64)         73792     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 8, 16, 64)         256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 16, 32, 32)        18464     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_22 (Ba  (None, 16, 32, 32)        128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2D  (None, 32, 64, 16)        4624      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_23 (Ba  (None, 32, 64, 16)        64        \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2D  (None, 32, 64, 3)         51        \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 282339 (1.08 MB)\n",
      "Trainable params: 281859 (1.08 MB)\n",
      "Non-trainable params: 480 (1.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# verify the latent dimensions using the models above\n",
    "latent_dims = 1024+512+1024\n",
    "decoder = keras.models.Sequential([\n",
    "    # the comma makes tensorflow interpret latent_dims as a valid shape\n",
    "    keras.layers.Input(shape=(latent_dims, ), name=\"deepfake_encoding\"),\n",
    "    keras.layers.Reshape((4, 4, 160)), # 4x4x160 = 2560\n",
    "    keras.layers.Conv2DTranspose(128, 3, (1, 2), padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(64, 3, 2, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(32, 3, 2, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(16, 3, 2, padding='same', activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2DTranspose(3, 1, 1, padding='same', activation='sigmoid'),\n",
    "], name='face_decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(keras.Model):\n",
    "    \"\"\"The auto encoder stack represening the generator\"\"\"\n",
    "    def __init__(self, masked_id_encoder, reference_id_encoder, audio_encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.masked_id_encoder = masked_id_encoder\n",
    "        self.reference_id_encoder = reference_id_encoder\n",
    "        self.audio_encoder = audio_encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def call(self, x):\n",
    "        identity, reference, audio = x \n",
    "        id_encoding = self.masked_id_encoder(identity)\n",
    "        ref_encoding = self.reference_id_encoder(reference)\n",
    "        audio_encoding = self.audio_encoder(audio)\n",
    "        combined = tf.concat([id_encoding, ref_encoding, audio_encoding], -1) # dimension 0 is batch size\n",
    "        genenerated_mouth = self.decoder(combined) \n",
    "        return tf.concat([identity, genenerated_mouth], axis=-3) # combine generated mouth and original top half"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(keras.Model):\n",
    "    \"\"\"Deepfake Discriminator\"\"\"\n",
    "    def __init__(self, image_encoder, audio_encoder):\n",
    "        super().__init__()\n",
    "        self.image_encoder = image_encoder\n",
    "        self.audio_encoder = audio_encoder\n",
    "    \n",
    "    def call(self, x):\n",
    "        image, audio = x\n",
    "        image_encoding = self.image_encoder(image)\n",
    "        audio_encoding = self.audio_encoder(audio)\n",
    "\n",
    "        # L2-normalize the encoding tensors\n",
    "        image_encoding = tf.math.l2_normalize(image_encoding, axis=1)\n",
    "        audio_encoding = tf.math.l2_normalize(audio_encoding, axis=1)\n",
    "\n",
    "        # measures how much the face matches the audio\n",
    "        # will return nan without the 1e-12 offset due to https://github.com/tensorflow/tensorflow/issues/12071\n",
    "        return tf.norm((image_encoding - audio_encoding) + 1e-12, ord='euclidean', axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deepfake GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "\n",
    "class DeepfakeGAN(keras.Model):\n",
    "    \"\"\"The Deepfake Generative Adversarial Network model.\"\"\"\n",
    "    def __init__(self, generator, discriminator):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        Args:\n",
    "            generator The generator model\n",
    "            discriminator: The discriminator model\n",
    "            test_gen_data: The data to generate a constant human face for the gif\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.gen_loss_tracker = keras.metrics.Mean(name=\"generator_loss\")\n",
    "        self.disc_loss_tracker = keras.metrics.Mean(name=\"discriminator_loss\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.gen_loss_tracker, self.disc_loss_tracker]\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        \"\"\"\n",
    "        Compiles the GAN.\n",
    "        Args:\n",
    "            d_optimizer: The optimizer for the discriminator\n",
    "            g_optimizer: The optimizer for the generator\n",
    "            d_loss_fn: The loss function for the discriminator\n",
    "            g_loss_fn: The loss function for the generator\n",
    "        \"\"\"\n",
    "        super().compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.generator(x)\n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        \"\"\"\n",
    "        Trains the GAN for one epoch. Will only train on BATCH_SIZE-1 samples.\n",
    "        Args:\n",
    "            data: lists of real images and the audio spectrograms with correspondent indices\n",
    "        \"\"\"\n",
    "        x, original_image = data\n",
    "        masked_image, ref_image, spectrogram_window, unsync_window = x\n",
    "\n",
    "        batch_size = tf.shape(original_image)[0]\n",
    "\n",
    "        # Use the generator to generate images\n",
    "        generated_images = self.generator((masked_image, ref_image, spectrogram_window))\n",
    "\n",
    "        train_unsync = tf.random.uniform(()) < 0.5 # 50/50\n",
    "        if not train_unsync:\n",
    "            # Add real images to batch\n",
    "            combined_images = tf.concat(\n",
    "                [generated_images, original_image], axis=0\n",
    "                ) \n",
    "            combined_audio = tf.concat(\n",
    "                [spectrogram_window, spectrogram_window], axis=0\n",
    "                )\n",
    "        else:\n",
    "            # Add real images to batch\n",
    "            combined_images = tf.concat(\n",
    "                [original_image, original_image], axis=0\n",
    "                ) \n",
    "            combined_audio = tf.concat(\n",
    "                [unsync_window, spectrogram_window], axis=0\n",
    "                )\n",
    "        # Discriminator labels for combined_images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "            )\n",
    "        labels += 0.05 * tf.random.uniform(tf.shape(labels)) # Add random noise to the labels\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as disc_tape:\n",
    "            predictions = self.discriminator((combined_images, combined_audio))\n",
    "            d_loss = self.d_loss_fn(labels, predictions)\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        grads = disc_tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        # Train the generator\n",
    "        with tf.GradientTape() as gen_tape:\n",
    "            # Use the generator to generate images, must be done again to create connection\n",
    "            generated_images = self.generator((masked_image, ref_image, spectrogram_window))\n",
    "            predictions = self.discriminator((generated_images, spectrogram_window))\n",
    "            # Labels if all real images\n",
    "            real = tf.zeros((batch_size, 1))\n",
    "            # Staggering loss function as mse is small\n",
    "            g_loss = hp.disc_wt *(self.d_loss_fn(real, predictions)) + self.g_loss_fn(original_image, generated_images)\n",
    "\n",
    "        # Compute gradients and update weights\n",
    "        grads = gen_tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "\n",
    "        return {\n",
    "                \"gen_loss\": self.gen_loss_tracker.result(),\n",
    "                \"disc_loss\": self.disc_loss_tracker.result(),\n",
    "            }\n",
    "    \n",
    "    def test_step(self, data):\n",
    "        x, original_images = data\n",
    "        masked_image, ref_image, spectrogram_window, _ = x\n",
    "\n",
    "        batch_size = tf.shape(original_images)[0]\n",
    "\n",
    "        # inference\n",
    "        generated_images = self.generator((masked_image, ref_image, spectrogram_window))\n",
    "        predictions = self.discriminator((generated_images, spectrogram_window))\n",
    "\n",
    "        # calculate loss\n",
    "        d_loss = self.d_loss_fn(tf.ones((batch_size, 1)), predictions)\n",
    "        g_loss = hp.disc_wt *(self.d_loss_fn(tf.zeros((batch_size, 1)), predictions)) + self.g_loss_fn(original_image, generated_images)\n",
    "\n",
    "        # Monitor loss.\n",
    "        self.gen_loss_tracker.update_state(g_loss)\n",
    "        self.disc_loss_tracker.update_state(d_loss)\n",
    "\n",
    "        return {\n",
    "                \"test_gen_loss\": self.gen_loss_tracker.result(),\n",
    "                \"test_disc_loss\": self.disc_loss_tracker.result(),\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator(masked_id_encoder, identity_encoder, audio_encoder, decoder)\n",
    "discriminator = Discriminator(identity_encoder_disc, audio_encoder_disc)\n",
    "gan = DeepfakeGAN(generator, discriminator)\n",
    "gan.compile(\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=hp.disc_initial_learning_rate),\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    d_loss_fn=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    g_loss_fn=keras.losses.MeanAbsoluteError(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out prior logging data.\n",
    "!rm -rf logs/image\n",
    "\n",
    "test_data = next(x_test_iter)\n",
    "\n",
    "logdir = \"logs/image/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Define the basic TensorBoard callback.\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "file_writer_cm = tf.summary.create_file_writer(logdir + '/cm')\n",
    "\n",
    "def plot_to_image(figure):\n",
    "  \"\"\"Converts the matplotlib plot specified by 'figure' to a PNG image and\n",
    "  returns it. The supplied figure is closed and inaccessible after this call.\"\"\"\n",
    "  # Save the plot to a PNG in memory.\n",
    "  buf = io.BytesIO()\n",
    "  plt.savefig(buf, format='png')\n",
    "  # Closing the figure prevents it from being displayed directly inside\n",
    "  # the notebook.\n",
    "  plt.close(figure)\n",
    "  buf.seek(0)\n",
    "  # Convert PNG buffer to TF image\n",
    "  image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "  # Add the batch dimension\n",
    "  image = tf.expand_dims(image, 0)\n",
    "  return image\n",
    "\n",
    "def test_generate(epoch, logs):\n",
    "  # if epoch % 10 != 0: # only run every 10 epochs\n",
    "  #   return \n",
    "  \n",
    "  gan.save_weights(\"trained_models/unsync1000\")\n",
    "\n",
    "  x, original_images = test_data\n",
    "  masked_image, ref_image, spectrogram_window, _ = x\n",
    "\n",
    "  # This is so all layers run in inference mode (batchnorm).\n",
    "  predictions  = gan.generator((masked_image, ref_image, spectrogram_window))\n",
    "  d = gan.discriminator((predictions, spectrogram_window))\n",
    "  if tf.is_symbolic_tensor(predictions):\n",
    "    return\n",
    "\n",
    "  # if from_tensor:\n",
    "  #   original_images = original_images.numpy()\n",
    "  #   masked_image = masked_image.numpy()\n",
    "  #   # ref_image = ref_image.numpy()\n",
    "  #   # spectrogram_window = spectrogram_window.numpy()\n",
    "  #   predictions = predictions.numpy()\n",
    "  #   d = d.numpy()\n",
    "\n",
    "  batch_size = original_images.shape[0]\n",
    "\n",
    "  figure = plt.figure(figsize=(15, 6))\n",
    "  for i in range(batch_size):\n",
    "    # display original\n",
    "    ax = plt.subplot(3, batch_size, i + 1)\n",
    "    plt.imshow(original_images[i])\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, batch_size, i + 1 + batch_size)\n",
    "    plt.imshow(ref_image[i])\n",
    "    plt.title(\"reference\") # only show 3 floating points \n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(3, batch_size, i + 1 + 2*batch_size)\n",
    "    plt.imshow(predictions[i])\n",
    "    plt.title(\"d=\" + str(d[i].numpy()[0])) # only show 3 floating points \n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  with file_writer_cm.as_default():\n",
    "    tf.summary.image(\"Test Generation\", plot_to_image(figure), step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the per-epoch callback.\n",
    "cm_callback = keras.callbacks.LambdaCallback(on_epoch_end=test_generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-17 18:34:21.006003: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:442] Loaded cuDNN version 8700\n",
      "2024-05-17 18:34:23.601171: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7a905fc1c380 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-17 18:34:23.601198: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3070 Ti, Compute Capability 8.6\n",
      "2024-05-17 18:34:23.605057: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-05-17 18:34:23.666178: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 169s 2s/step - gen_loss: 0.1270 - disc_loss: 0.6634\n",
      "Epoch 2/200\n",
      "100/100 [==============================] - 155s 2s/step - gen_loss: 0.1265 - disc_loss: 0.6066\n",
      "Epoch 3/200\n",
      "100/100 [==============================] - 157s 2s/step - gen_loss: 0.1203 - disc_loss: 0.5125\n",
      "Epoch 4/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1270 - disc_loss: 0.5363\n",
      "Epoch 5/200\n",
      "100/100 [==============================] - 150s 2s/step - gen_loss: 0.1256 - disc_loss: 0.5188\n",
      "Epoch 6/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1199 - disc_loss: 0.5360\n",
      "Epoch 7/200\n",
      "100/100 [==============================] - 151s 2s/step - gen_loss: 0.1185 - disc_loss: 0.4965\n",
      "Epoch 8/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1235 - disc_loss: 0.5132\n",
      "Epoch 9/200\n",
      "100/100 [==============================] - 153s 2s/step - gen_loss: 0.1215 - disc_loss: 0.5348\n",
      "Epoch 10/200\n",
      "100/100 [==============================] - 157s 2s/step - gen_loss: 0.1224 - disc_loss: 0.5209 - val_test_gen_loss: 0.2293 - val_test_disc_loss: 0.1792\n",
      "Epoch 11/200\n",
      "100/100 [==============================] - 150s 2s/step - gen_loss: 0.1219 - disc_loss: 0.5354\n",
      "Epoch 12/200\n",
      "100/100 [==============================] - 155s 2s/step - gen_loss: 0.1275 - disc_loss: 0.5733\n",
      "Epoch 13/200\n",
      "100/100 [==============================] - 153s 2s/step - gen_loss: 0.1195 - disc_loss: 0.5426\n",
      "Epoch 14/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1232 - disc_loss: 0.5155\n",
      "Epoch 15/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1208 - disc_loss: 0.5356\n",
      "Epoch 16/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1227 - disc_loss: 0.5472\n",
      "Epoch 17/200\n",
      "100/100 [==============================] - 156s 2s/step - gen_loss: 0.1249 - disc_loss: 0.5172\n",
      "Epoch 18/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1199 - disc_loss: 0.5113\n",
      "Epoch 19/200\n",
      "100/100 [==============================] - 153s 2s/step - gen_loss: 0.1242 - disc_loss: 0.5444\n",
      "Epoch 20/200\n",
      "100/100 [==============================] - 158s 2s/step - gen_loss: 0.1150 - disc_loss: 0.5040 - val_test_gen_loss: 0.2288 - val_test_disc_loss: 0.1808\n",
      "Epoch 21/200\n",
      "100/100 [==============================] - 150s 2s/step - gen_loss: 0.1208 - disc_loss: 0.5098\n",
      "Epoch 22/200\n",
      "100/100 [==============================] - 155s 2s/step - gen_loss: 0.1266 - disc_loss: 0.5258\n",
      "Epoch 23/200\n",
      "100/100 [==============================] - 156s 2s/step - gen_loss: 0.1256 - disc_loss: 0.5566\n",
      "Epoch 24/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1183 - disc_loss: 0.5054\n",
      "Epoch 25/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1197 - disc_loss: 0.5111\n",
      "Epoch 26/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1217 - disc_loss: 0.5216\n",
      "Epoch 27/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1226 - disc_loss: 0.5306\n",
      "Epoch 28/200\n",
      "100/100 [==============================] - 151s 2s/step - gen_loss: 0.1221 - disc_loss: 0.5298\n",
      "Epoch 29/200\n",
      "100/100 [==============================] - 156s 2s/step - gen_loss: 0.1203 - disc_loss: 0.5298\n",
      "Epoch 30/200\n",
      "100/100 [==============================] - 158s 2s/step - gen_loss: 0.1228 - disc_loss: 0.5466 - val_test_gen_loss: 0.2297 - val_test_disc_loss: 0.1791\n",
      "Epoch 31/200\n",
      "100/100 [==============================] - 152s 2s/step - gen_loss: 0.1219 - disc_loss: 0.4976\n",
      "Epoch 32/200\n",
      "100/100 [==============================] - 153s 2s/step - gen_loss: 0.1225 - disc_loss: 0.5131\n",
      "Epoch 33/200\n",
      "100/100 [==============================] - 156s 2s/step - gen_loss: 0.1255 - disc_loss: 0.5014\n",
      "Epoch 34/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1187 - disc_loss: 0.4918\n",
      "Epoch 35/200\n",
      "100/100 [==============================] - 153s 2s/step - gen_loss: 0.1141 - disc_loss: 0.4965\n",
      "Epoch 36/200\n",
      "100/100 [==============================] - 155s 2s/step - gen_loss: 0.1226 - disc_loss: 0.5014\n",
      "Epoch 37/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1196 - disc_loss: 0.5031\n",
      "Epoch 38/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1221 - disc_loss: 0.5320\n",
      "Epoch 39/200\n",
      "100/100 [==============================] - 153s 2s/step - gen_loss: 0.1207 - disc_loss: 0.5179\n",
      "Epoch 40/200\n",
      "100/100 [==============================] - 158s 2s/step - gen_loss: 0.1218 - disc_loss: 0.5287 - val_test_gen_loss: 0.2272 - val_test_disc_loss: 0.1836\n",
      "Epoch 41/200\n",
      "100/100 [==============================] - 149s 2s/step - gen_loss: 0.1207 - disc_loss: 0.5176\n",
      "Epoch 42/200\n",
      "100/100 [==============================] - 156s 2s/step - gen_loss: 0.1205 - disc_loss: 0.5032\n",
      "Epoch 43/200\n",
      "100/100 [==============================] - 153s 2s/step - gen_loss: 0.1160 - disc_loss: 0.4788\n",
      "Epoch 44/200\n",
      "100/100 [==============================] - 152s 2s/step - gen_loss: 0.1213 - disc_loss: 0.5360\n",
      "Epoch 45/200\n",
      "100/100 [==============================] - 151s 2s/step - gen_loss: 0.1208 - disc_loss: 0.5195\n",
      "Epoch 46/200\n",
      "100/100 [==============================] - 153s 2s/step - gen_loss: 0.1246 - disc_loss: 0.5465\n",
      "Epoch 47/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1238 - disc_loss: 0.5451\n",
      "Epoch 48/200\n",
      "100/100 [==============================] - 156s 2s/step - gen_loss: 0.1210 - disc_loss: 0.5102\n",
      "Epoch 49/200\n",
      "100/100 [==============================] - 153s 2s/step - gen_loss: 0.1167 - disc_loss: 0.5011\n",
      "Epoch 50/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1169 - disc_loss: 0.5085 - val_test_gen_loss: 0.2271 - val_test_disc_loss: 0.1842\n",
      "Epoch 51/200\n",
      "100/100 [==============================] - 148s 1s/step - gen_loss: 0.1176 - disc_loss: 0.5372\n",
      "Epoch 52/200\n",
      "100/100 [==============================] - 154s 2s/step - gen_loss: 0.1213 - disc_loss: 0.5106\n",
      "Epoch 53/200\n",
      "100/100 [==============================] - 153s 2s/step - gen_loss: 0.1208 - disc_loss: 0.5197\n",
      "Epoch 54/200\n",
      "100/100 [==============================] - 152s 2s/step - gen_loss: 0.1186 - disc_loss: 0.5075\n",
      "Epoch 55/200\n",
      "100/100 [==============================] - 149s 2s/step - gen_loss: 0.1211 - disc_loss: 0.5017\n",
      "Epoch 56/200\n",
      "100/100 [==============================] - 151s 2s/step - gen_loss: 0.1255 - disc_loss: 0.5539\n",
      "Epoch 57/200\n",
      "100/100 [==============================] - 168s 2s/step - gen_loss: 0.1244 - disc_loss: 0.5295\n",
      "Epoch 58/200\n",
      "100/100 [==============================] - 162s 2s/step - gen_loss: 0.1227 - disc_loss: 0.5357\n",
      "Epoch 59/200\n",
      "100/100 [==============================] - 162s 2s/step - gen_loss: 0.1218 - disc_loss: 0.5421\n",
      "Epoch 60/200\n",
      "100/100 [==============================] - 160s 2s/step - gen_loss: 0.1202 - disc_loss: 0.5225 - val_test_gen_loss: 0.2277 - val_test_disc_loss: 0.1836\n",
      "Epoch 61/200\n",
      " 42/100 [===========>..................] - ETA: 1:12 - gen_loss: 0.1178 - disc_loss: 0.5699"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m gan\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrained_models/unsync1000\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcm_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/QMIND/deepfake-lip-sync/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Projects/QMIND/deepfake-lip-sync/.venv/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Documents/Projects/QMIND/deepfake-lip-sync/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Projects/QMIND/deepfake-lip-sync/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Projects/QMIND/deepfake-lip-sync/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:876\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    880\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Projects/QMIND/deepfake-lip-sync/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Projects/QMIND/deepfake-lip-sync/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Projects/QMIND/deepfake-lip-sync/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/Projects/QMIND/deepfake-lip-sync/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Projects/QMIND/deepfake-lip-sync/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/Projects/QMIND/deepfake-lip-sync/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gan.load_weights(\"trained_models/unsync1000\")\n",
    "history = gan.fit(x_train, epochs=200, verbose=1, steps_per_epoch=100, \n",
    "                  validation_data=x_test, validation_steps=1, validation_freq=10, callbacks=[tensorboard_callback, cm_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.save_weights(\"trained_models/unsync1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_generate(next(x_test_iter), gan, save=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
